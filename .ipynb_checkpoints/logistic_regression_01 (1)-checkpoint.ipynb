{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "#train = pd.read_csv(f\"dataset_original.csv\")\n",
    "#train = pd.read_csv(f\"dataset_160k.csv\")\n",
    "train = pd.read_csv(f\"dataset_30k.csv\")\n",
    "\n",
    "# shuffle the dataset\n",
    "train = train.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PreferedOrderCat\n",
    "train.loc[train[\"PreferedOrderCat\"] == \"Laptop & Accessory\", \"PreferedOrderCat\"] = \"Laptop_Accessory\"\n",
    "train.loc[train[\"PreferedOrderCat\"] == \"Mobile Phone\", \"PreferedOrderCat\"] = \"Mobile\"\n",
    "\n",
    "#PreferredPaymentMode\n",
    "train.loc[train[\"PreferredPaymentMode\"] == \"Debit Card\", \"PreferredPaymentMode\"] = \"DebitCard\"\n",
    "train.loc[train[\"PreferredPaymentMode\"] == \"Credit Card\", \"PreferredPaymentMode\"] = \"CreditCard\"\n",
    "train.loc[train[\"PreferredPaymentMode\"] == \"CC\", \"PreferredPaymentMode\"] = \"CreditCard\"\n",
    "train.loc[train[\"PreferredPaymentMode\"] == \"E wallet\", \"PreferredPaymentMode\"] = \"Ewallet\"\n",
    "train.loc[train[\"PreferredPaymentMode\"] == \"Cash on Delivery\", \"PreferredPaymentMode\"] = \"COD\"\n",
    "\n",
    "#PreferredLoginDevice\n",
    "train.loc[train[\"PreferredLoginDevice\"] == \"Mobile Phone\", \"PreferredLoginDevice\"] = \"Mobile\"\n",
    "train.loc[train[\"PreferredLoginDevice\"] == \"Phone\", \"PreferredLoginDevice\"] = \"Mobile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'CustomerID' column since it's not useful for prediction\n",
    "X = train.drop('CustomerID', axis=1)\n",
    "\n",
    "# Separate the target variable from the rest of the dataset\n",
    "y = train['Churn']\n",
    "\n",
    "X = X.drop(columns=['Churn'], axis=1)\n",
    "#X = X.drop(columns=[], axis=1)\n",
    "\n",
    "# Perform one-hot encoding on the categorical features\n",
    "cat_cols = ['PreferredLoginDevice', 'PreferredPaymentMode', 'PreferedOrderCat','Gender','MaritalStatus']\n",
    "X = pd.get_dummies(X, columns=cat_cols)\n",
    "\n",
    "# Fill missing values with mean\n",
    "#X = X.fillna(0)\n",
    "#X.fillna(X.mode().iloc[0], inplace=True)\n",
    "X.fillna(X.mean(), inplace=True)\n",
    "# X.fillna(X.median(), inplace=True)\n",
    "# X.fillna(method='ffill', inplace=True)\n",
    "# X.fillna(method='bfill', inplace=True)\n",
    "#X.interpolate(method='linear', inplace=True)\n",
    "\n",
    "#y = y.fillna(0)\n",
    "#y.fillna(y.mode().iloc[0], inplace=True)\n",
    "y.fillna(y.mean(), inplace=True)\n",
    "# y.fillna(y.median(), inplace=True)\n",
    "# y.fillna(method='ffill', inplace=True)\n",
    "# y.fillna(method='bfill', inplace=True)\n",
    "#y.interpolate(method='linear', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30630, 30)\n",
      "(30630,)\n"
     ]
    }
   ],
   "source": [
    "num_cols = X.columns.tolist()\n",
    "for col in cat_cols:\n",
    "    if col in num_cols:\n",
    "        num_cols.remove(col)\n",
    "\n",
    "# Normalize the numerical features using min-max scaling\n",
    "X[num_cols] = (X[num_cols] - X[num_cols].min()) / (X[num_cols].max() - X[num_cols].min())\n",
    "\n",
    "# Convert the target variable to binary (0 or 1)\n",
    "y = y.astype(int)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_smote(X, y, random_state=None):\n",
    "    \"\"\"\n",
    "    Applies SMOTE to the input features (X) and target variable (y) to balance the dataset.\n",
    "    \n",
    "    Parameters:\n",
    "    X: numpy array or pandas DataFrame with the input features\n",
    "    y: numpy array or pandas Series with the target variable\n",
    "    random_state: int, default=None, controls the randomness of the SMOTE algorithm\n",
    "    \n",
    "    Returns:\n",
    "    X_resampled: numpy array with the resampled input features\n",
    "    y_resampled: numpy array with the resampled target variable\n",
    "    \"\"\"\n",
    "    smote = SMOTE(random_state=random_state)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50312, 30)\n",
      "(50312,)\n"
     ]
    }
   ],
   "source": [
    "X, y = apply_smote(X, y, random_state=42)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40249, 30) (40249,) (10063, 30) (10063,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "y_test = np.array(y_test).reshape(-1, 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 10000\n",
    "\n",
    "patience = 5\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    " \n",
    "    def loss_function(self, y_pred, y_true):\n",
    "        loss = F.binary_cross_entropy(y_pred, y_true)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Define the optimizer\n",
    "# Set the learning rate and weight decay (L2 regularization) for the Adam optimizer\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.001\n",
    "\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape\n",
    "type(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = X_train.values\n",
    "train_labels = y_train.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Loss=0.5813\n",
      "Epoch 1000: Loss=0.5688\n",
      "Epoch 2000: Loss=0.5588\n",
      "Epoch 3000: Loss=0.5510\n",
      "Epoch 4000: Loss=0.5449\n",
      "Epoch 5000: Loss=0.5406\n",
      "Epoch 6000: Loss=0.5378\n",
      "Epoch 7000: Loss=0.5364\n",
      "Epoch 8000: Loss=0.5360\n",
      "Epoch 9000: Loss=0.5359\n",
      "Epoch 9999: Loss=0.5359\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    inputs = torch.from_numpy(train_data).float()\n",
    "    labels = torch.from_numpy(train_labels).float().view(-1, 1)\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss={loss.item():.4f}\")\n",
    "\n",
    "print(f\"Epoch {epoch}: Loss={loss.item():.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "inputs = torch.from_numpy(test_data).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = torch.from_numpy(y_test).float().view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = outputs.round().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8650\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.mean(predicted == y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38\n",
      "4\n",
      "Precision: 0.9047619047619048, Recall: 0.34545454545454546\n",
      "F1 Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "# Convert the predictions to binary labels (0 or 1)\n",
    "y_pred_binary = (predicted > 0.5).astype(int)\n",
    "\n",
    "# calculate confusion matrix\n",
    "confusion = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "# calculate precision and recall\n",
    "precision = confusion[1, 1] / (confusion[1, 1] + confusion[0, 1])\n",
    "recall = confusion[1, 1] / (confusion[1, 1] + confusion[1, 0])\n",
    "\n",
    "# calculate F1 score\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "print(confusion[1,1])\n",
    "print(confusion[0,1])\n",
    "print(f'Precision: { precision}, Recall: {recall}')\n",
    "print('F1 Score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
